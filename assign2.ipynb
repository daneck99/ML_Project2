{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyPu9Z768IGTxpE8qIttDFsU"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":13613695,"sourceType":"datasetVersion","datasetId":8651649},{"sourceId":4982782,"sourceType":"datasetVersion","datasetId":2889918}],"dockerImageVersionId":31154,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##   STEP0: 런타임 준비 + 기본 설정\n\n\n","metadata":{"id":"OpJnRNwZ7Uvd"}},{"cell_type":"code","source":"#!pip -q install -U sentence-transformers transformers peft datasets\n\nimport os, sys, json\nimport numpy as np, pandas as pd\nprint(\"Python:\", sys.version)\n\n# 경로/하이퍼파라미터 공통\nDEBERTA_DIR = \"/kaggle/input/deberta-v3-small-local\"\nQWEN3_DIR = \"/kaggle/input/all-minilm-l6-v2/all-MiniLM-L6-v2\"  \nDATA_DIR = \"/kaggle/input/llm-classification-finetuning\"  # Colab/로컬이면 적절히 교체\nWORK_DIR = \"/kaggle/working\"\n\nBASE_ARGS = {\n    \"DATA_DIR\": DATA_DIR,\n    \"WORK_DIR\": WORK_DIR,\n    \"train_path\": f\"{DATA_DIR}/train.csv\",\n    \"test_path\":  f\"{DATA_DIR}/test.csv\",\n    \"submit_path\": f\"{DATA_DIR}/sample_submission.csv\",\n    \"embed_model_dir\": QWEN3_DIR,  \n    \"embed_batch_size\": 64,         \n    \"random_state\": 42,\n    \"val_size\": 0.2,\n}\n\n# 파일 존재 확인\nfor k in [\"train_path\",\"test_path\",\"submit_path\"]:\n    print(k, os.path.exists(BASE_ARGS[k]), \"->\", BASE_ARGS[k])\n","metadata":{"id":"88EyYNsJ7Uc7","trusted":true,"execution":{"iopub.status.busy":"2025-11-06T13:40:27.107611Z","iopub.execute_input":"2025-11-06T13:40:27.107968Z","iopub.status.idle":"2025-11-06T13:40:27.118400Z","shell.execute_reply.started":"2025-11-06T13:40:27.107941Z","shell.execute_reply":"2025-11-06T13:40:27.117257Z"}},"outputs":[{"name":"stdout","text":"Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\ntrain_path True -> /kaggle/input/llm-classification-finetuning/train.csv\ntest_path True -> /kaggle/input/llm-classification-finetuning/test.csv\nsubmit_path True -> /kaggle/input/llm-classification-finetuning/sample_submission.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## STEP0: Data preprocessing + labeling","metadata":{"id":"ig3HnVFV7jYp"}},{"cell_type":"code","source":"from typing import Dict, Tuple, Optional, List\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import MaxAbsScaler\n\ndef load_csvs(cfg: Dict):\n    train = pd.read_csv(cfg[\"train_path\"])\n    test  = pd.read_csv(cfg[\"test_path\"])\n    submit= pd.read_csv(cfg[\"submit_path\"])\n    print(f\"[io] train:{train.shape}, test:{test.shape}, submit:{submit.shape}\")\n    return train, test, submit\n\ndef standardize_columns(df: pd.DataFrame) -> pd.DataFrame:\n    low = {c.lower(): c for c in df.columns}\n    if \"response_a\" in low: df = df.rename(columns={low[\"response_a\"]: \"response_A\"})\n    if \"response_b\" in low: df = df.rename(columns={low[\"response_b\"]: \"response_B\"})\n    if \"prompt\" not in df.columns: df[\"prompt\"] = \"\"\n    return df\n    \ndef build_label_threeway(train: pd.DataFrame) -> pd.DataFrame:\n    low = {c.lower(): c for c in train.columns}\n    need = {\"winner_model_a\",\"winner_model_b\",\"winner_tie\"}\n    if not need.issubset(set(low)):\n        raise ValueError(\"3-class 라벨 생성 불가: winner_* 세 컬럼 필요\")\n\n    a = pd.to_numeric(train[low[\"winner_model_a\"]], errors=\"coerce\").fillna(0).astype(int)\n    b = pd.to_numeric(train[low[\"winner_model_b\"]], errors=\"coerce\").fillna(0).astype(int)\n    t = pd.to_numeric(train[low[\"winner_tie\"]],     errors=\"coerce\").fillna(0).astype(int)\n\n    # 각 행에서 하나만 1이라고 가정(여러 개 1인 이상치는 A/B/tie 우선순위로 최대값 선택)\n    label3 = np.argmax(np.stack([a.values, b.values, t.values], axis=1), axis=1).astype(int)\n\n    out = train.copy()\n    out[\"label\"] = label3  # 0:A, 1:B, 2:tie\n    print(\"[pre/3way] shape:\", out.shape,\n          \" label counts:\", dict(pd.Series(label3).value_counts().sort_index()))\n    return out\n\ndef save_submission_threecols(test_df: pd.DataFrame,\n                              probs_3: np.ndarray,  # shape (N, 3) → softmax된 확률\n                              out_path: str):\n    assert probs_3.ndim == 2 and probs_3.shape[1] == 3, \"probs_3 must be (N,3)\"\n    p = np.clip(probs_3, 1e-7, 1-1e-7)\n    p = p / p.sum(axis=1, keepdims=True)  # 혹시 모를 드리프트 교정\n\n    sub = pd.DataFrame({\n        \"id\": test_df[\"id\"].values,\n        \"winner_model_a\": p[:, 0],\n        \"winner_model_b\": p[:, 1],\n        \"winner_tie\":     p[:, 2],\n    })\n\n    # sanity check\n    s = sub[[\"winner_model_a\",\"winner_model_b\",\"winner_tie\"]].sum(1).to_numpy()\n    assert np.allclose(s, 1.0, atol=1e-6), \"probabilities must sum to 1\"\n\n    sub.to_csv(out_path, index=False)\n    print(\"[save]\", out_path)\n    print(sub.head())\n\nfrom sklearn.preprocessing import MaxAbsScaler\ndef stable_softmax(logits):\n    # logits: (n, C)\n    m = logits.max(axis=1, keepdims=True)\n    z = logits - m\n    np.clip(z, -50, 50, out=z)     # 안전 클리핑\n    ez = np.exp(z, dtype=np.float64)\n    s = ez.sum(axis=1, keepdims=True)\n    # s==0 방지\n    s[s == 0] = 1.0\n    p = ez / s\n    # NaN/Inf 방지\n    p = np.nan_to_num(p, nan=1.0/p.shape[1], posinf=1.0/p.shape[1], neginf=0.0)\n    # 정규화 재확인\n    p = p / p.sum(axis=1, keepdims=True)\n    return p\n\ndef _stack_with_scaled_handcrafted(X, Xt, train, test):\n    # 부가 특성 스케일링\n    extra_tr = np.hstack([add_length_feats(train).values,\n                          add_bias_feats(train).values]).astype(np.float32)\n    extra_te = np.hstack([add_length_feats(test).values,\n                          add_bias_feats(test).values]).astype(np.float32)\n    scaler = MaxAbsScaler()  # 희소-친화\n    extra_tr = scaler.fit_transform(extra_tr)\n    extra_te = scaler.transform(extra_te)\n    # 희소 hstack\n    X  = hstack([X,  csr_matrix(extra_tr)], format=\"csr\")\n    Xt = hstack([Xt, csr_matrix(extra_te)], format=\"csr\")\n    return X, Xt\n\ndef _safe_proba_from_clf(clf, X, n_classes=3):\n    # 항상 decision_function + 안정 소프트맥스 사용 (predict_proba 불안정 회피)\n    logits = clf.decision_function(X)  # (n,C) 또는 (n,) 이진이면 (n,)\n    if logits.ndim == 1:\n        # 이진이면 2열로 변환\n        logits = np.vstack([-logits, logits]).T\n    P = stable_softmax(logits)\n    # 클래스 정렬 보정 (clf.classes_ 순서를 0,1,2로 맞춤)\n    order = [list(clf.classes_).index(c) for c in sorted(clf.classes_)]\n    P = P[:, order]\n    # 만약 클래스가 3개 미만으로 학습되면(극히 드묾) 누락된 열을 0으로 패드\n    if P.shape[1] < n_classes:\n        P_pad = np.zeros((P.shape[0], n_classes), dtype=P.dtype)\n        for i, c in enumerate(sorted(clf.classes_)):\n            P_pad[:, c] = P[:, i]\n        P = P_pad\n    return P","metadata":{"id":"dJWKTLd6726Z","trusted":true,"execution":{"iopub.status.busy":"2025-11-06T13:40:30.198120Z","iopub.execute_input":"2025-11-06T13:40:30.198531Z","iopub.status.idle":"2025-11-06T13:40:30.227351Z","shell.execute_reply.started":"2025-11-06T13:40:30.198502Z","shell.execute_reply":"2025-11-06T13:40:30.226060Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"##STEP 1:TF-IDF Baseline","metadata":{"id":"459G-OVX7590"}},{"cell_type":"code","source":"from scipy.sparse import hstack, csr_matrix\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss, accuracy_score\nimport numpy as np\nimport pandas as pd\nimport os\n\ndef add_length_feats(df):\n    f = pd.DataFrame(index=df.index)\n    f[\"len_prompt\"]=df[\"prompt\"].astype(str).str.len()\n    f[\"len_A\"]=df[\"response_A\"].astype(str).str.len()\n    f[\"len_B\"]=df[\"response_B\"].astype(str).str.len()\n    f[\"diff_len\"]=f[\"len_A\"]-f[\"len_B\"]\n    return f.astype(np.float32)\n\ndef add_bias_feats(df):\n    sA=df[\"response_A\"].astype(str).str.strip()\n    sB=df[\"response_B\"].astype(str).str.strip()\n    f = pd.DataFrame(index=df.index)\n    f[\"starts_with_quote_A\"]=sA.str.startswith('\"').astype(int)\n    f[\"starts_with_quote_B\"]=sB.str.startswith('\"').astype(int)\n    f[\"verbosity_A\"]=sA.str.len()\n    f[\"verbosity_B\"]=sB.str.len()\n    f[\"verbosity_diff\"]=f[\"verbosity_A\"]-f[\"verbosity_B\"]\n    return f.astype(np.float32)\n\ndef _ensure_proba_order(proba, clf_classes, target_order=(0,1,2)):\n    \"\"\"clf.predict_proba의 열 순서를 target_order에 맞추어 재정렬\"\"\"\n    # clf_classes: 예) array([0,1,2])\n    idx = [list(clf_classes).index(c) for c in target_order]\n    return proba[:, idx]\n\ndef run_step1_tfidf(cfg: Dict, max_features=20000, ngram=(1,2),\n                    use_logreg=False, out_csv=\"submission_step1.csv\"):\n    train, test, submit = load_csvs(cfg)\n    train = standardize_columns(train); test = standardize_columns(test)\n    train = build_label_threeway(train)  # y ∈ {0,1,2}\n\n    vec = TfidfVectorizer(max_features=max_features, ngram_range=ngram, dtype=np.float32)\n    vec.fit(pd.concat([train[\"response_A\"], train[\"response_B\"]]).astype(str))\n    XA, XB = vec.transform(train[\"response_A\"]), vec.transform(train[\"response_B\"])\n    XtA, XtB = vec.transform(test[\"response_A\"]), vec.transform(test[\"response_B\"])\n    X, Xt = hstack([XA,XB], format=\"csr\"), hstack([XtA,XtB], format=\"csr\")\n\n    # 수작업 feature + 스케일링\n    X, Xt = _stack_with_scaled_handcrafted(X, Xt, train, test)\n    y = train[\"label\"].astype(int).values\n\n    # 모델 선택\n    if use_logreg:\n        clf = LogisticRegression(\n            solver=\"saga\", max_iter=300, n_jobs=-1, verbose=0,\n            multi_class=\"multinomial\", random_state=cfg[\"random_state\"]\n        )\n    else:\n        clf = SGDClassifier(loss=\"log_loss\", max_iter=1000,\n                            tol=1e-3, random_state=cfg[\"random_state\"])\n\n    # train/val split\n    X_tr, X_val, y_tr, y_val = train_test_split(\n        X, y, test_size=cfg[\"val_size\"], stratify=y, random_state=cfg[\"random_state\"]\n    )\n\n    # 학습\n    clf.fit(X_tr, y_tr)\n\n    # 확률 예측 (항상 안정 softmax 사용)\n    p_tr  = _safe_proba_from_clf(clf, X_tr, n_classes=3)\n    p_val = _safe_proba_from_clf(clf, X_val, n_classes=3)\n\n    # 손실 및 지표 계산\n    train_loss = log_loss(y_tr, p_tr, labels=[0,1,2])\n    val_loss   = log_loss(y_val, p_val, labels=[0,1,2])\n    val_logloss = val_loss  # 별도 표기용 (Kaggle metric 동일)\n    val_acc = accuracy_score(y_val, p_val.argmax(axis=1))\n\n    print(f\"[step1] Train Loss: {train_loss:.4f}\")\n    print(f\"[step1] Val   Loss: {val_loss:.4f}\")\n    print(f\"[step1] Val LogLoss (Kaggle metric): {val_logloss:.4f}\")\n    print(f\"[step1] Val Acc: {val_acc*100:.2f}%\")\n\n    # 전체 데이터로 재학습 후 test 예측\n    clf.fit(X, y)\n    p_test = _safe_proba_from_clf(clf, Xt, n_classes=3)\n    save_submission_threecols(submit, p_test, os.path.join(cfg[\"WORK_DIR\"], out_csv))\n\n#실행\nrun_step1_tfidf(BASE_ARGS)\n","metadata":{"id":"iJfXlk9j8JyM","trusted":true,"execution":{"iopub.status.busy":"2025-11-06T13:40:33.808631Z","iopub.execute_input":"2025-11-06T13:40:33.808947Z","iopub.status.idle":"2025-11-06T13:42:37.884890Z","shell.execute_reply.started":"2025-11-06T13:40:33.808925Z","shell.execute_reply":"2025-11-06T13:42:37.883521Z"}},"outputs":[{"name":"stdout","text":"[io] train:(57477, 9), test:(3, 4), submit:(3, 4)\n[pre/3way] shape: (57477, 10)  label counts: {0: 20064, 1: 19652, 2: 17761}\n[step1] Train Loss: 0.8882\n[step1] Val   Loss: 1.0481\n[step1] Val LogLoss (Kaggle metric): 1.0481\n[step1] Val Acc: 46.76%\n[save] /kaggle/working/submission_step1.csv\n        id  winner_model_a  winner_model_b  winner_tie\n0   136060        0.128584        0.249266    0.622150\n1   211333        0.482830        0.241475    0.275695\n2  1233961        0.323471        0.449874    0.226655\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## STEP2","metadata":{"id":"M4XjVxoC8l7X"}},{"cell_type":"code","source":"# =========================\n# Step2: Fast Embedding Model (MiniLM/E5/BGE) + tqdm + 3-class OVR\n# =========================\nimport os, time, numpy as np, pandas as pd, torch\nfrom tqdm.auto import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import log_loss\n\n# 1) 범용 임베더: sentence-transformers 우선, 없으면 HF로 폴백(mean pooling)\nclass FastEmbedder:\n    def __init__(self, model_path_or_name: str,\n                 normalize: bool=True, max_length: int=256,\n                 use_instruction: bool=False):\n        self.normalize = normalize\n        self.max_length = max_length\n        self.use_instruction = use_instruction\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n        self.backend = \"st\"\n        try:\n            from sentence_transformers import SentenceTransformer\n            if os.path.exists(model_path_or_name):\n                print(\"[embed] sentence-transformers local:\", model_path_or_name)\n                self.st = SentenceTransformer(model_path_or_name, device=self.device)\n            else:\n                print(\"[embed] sentence-transformers hub:\", model_path_or_name)\n                self.st = SentenceTransformer(model_path_or_name, device=self.device)\n        except Exception as e:\n            print(\"[embed] ST import failed, fallback HF:\", e)\n            self.backend = \"hf\"\n            from transformers import AutoTokenizer, AutoModel\n            self.tok = AutoTokenizer.from_pretrained(model_path_or_name, use_fast=True)\n            self.model = AutoModel.from_pretrained(model_path_or_name).to(self.device).eval()\n\n        # e5/bge instruction prefix 힌트\n        lname = model_path_or_name.lower()\n        self.is_e5  = \"e5\" in lname\n        self.is_bge = \"bge\" in lname\n\n    def _maybe_prefix(self, series, kind):\n        # kind: \"prompt\" or \"response\"\n        if not self.use_instruction:\n            return series.astype(str)\n        s = series.astype(str)\n        if self.is_e5 or self.is_bge:\n            if kind == \"prompt\":\n                return \"query: \" + s\n            else:\n                return \"passage: \" + s\n        return s\n\n    @torch.no_grad()\n    def encode(self, series, batch_size=256, desc=\"Embedding\", kind=\"response\"):\n        texts = self._maybe_prefix(series, kind)\n        arr = texts.astype(str).tolist()\n\n        if self.backend == \"st\":\n            # ST가 내부 배치/FP16 최적화 수행\n            embs = self.st.encode(\n                arr, batch_size=batch_size, show_progress_bar=True,\n                normalize_embeddings=self.normalize\n            )\n            return np.asarray(embs, dtype=np.float32)\n\n        # HF 폴백(mean pooling)\n        from transformers import logging as hf_logging\n        hf_logging.set_verbosity_error()\n        out = []\n        t0 = time.time()\n        for i in tqdm(range(0, len(arr), batch_size), desc=desc, ncols=90):\n            batch = arr[i:i+batch_size]\n            toks = self.tok(\n                batch, padding=True, truncation=True,\n                max_length=self.max_length, return_tensors=\"pt\"\n            ).to(self.device)\n            hidden = self.model(**toks).last_hidden_state  # (B,T,H)\n            mask = toks[\"attention_mask\"].unsqueeze(-1)\n            vecs = (hidden * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1)\n            if self.normalize:\n                vecs = torch.nn.functional.normalize(vecs, p=2, dim=1)\n            out.append(vecs.float().cpu().numpy())\n        print(f\"[{desc}] {len(arr)} rows in {time.time()-t0:.1f}s\")\n        return np.vstack(out).astype(np.float32)\n\ndef run_step2_embed_fast(cfg: dict,\n                         model_path_or_name: str,\n                         bs_embed: int = 256,\n                         out_csv: str = \"submission_step2_fast.csv\",\n                         max_length: int = 256,\n                         use_instruction: bool = False):\n    t0 = time.time()\n    # 0) 데이터\n    train, test, _ = load_csvs(cfg)\n    train = standardize_columns(train); test = standardize_columns(test)\n    train = build_label_threeway(train)  # label in {0:A,1:B,2:tie}\n    for c in [\"prompt\",\"response_A\",\"response_B\"]:\n        if c not in train.columns: train[c] = \"\"\n        if c not in test.columns:  test[c]  = \"\"\n\n    # 1) 임베딩\n    emb = FastEmbedder(model_path_or_name, normalize=True,\n                       max_length=max_length, use_instruction=use_instruction)\n    with tqdm(total=6, desc=\"[embed] all\", ncols=90) as pbar:\n        Ep_tr = emb.encode(train[\"prompt\"],     batch_size=bs_embed, desc=\"Train P\", kind=\"prompt\");  pbar.update(1)\n        Ea_tr = emb.encode(train[\"response_A\"], batch_size=bs_embed, desc=\"Train A\", kind=\"response\"); pbar.update(1)\n        Eb_tr = emb.encode(train[\"response_B\"], batch_size=bs_embed, desc=\"Train B\", kind=\"response\"); pbar.update(1)\n        Ep_te = emb.encode(test[\"prompt\"],      batch_size=bs_embed, desc=\"Test  P\", kind=\"prompt\");  pbar.update(1)\n        Ea_te = emb.encode(test[\"response_A\"],  batch_size=bs_embed, desc=\"Test  A\", kind=\"response\"); pbar.update(1)\n        Eb_te = emb.encode(test[\"response_B\"],  batch_size=bs_embed, desc=\"Test  B\", kind=\"response\"); pbar.update(1)\n\n    # 2) 피처 (그대로 재사용)\n    def make_feats(Ep, Ea, Eb, df):\n        d_abs = np.abs(Ea - Eb)      # ~[-1,1]\n        d_mul = Ea * Eb              # ~[-1,1]\n        la = df[\"response_A\"].astype(str).str.len().to_numpy().reshape(-1,1)\n        lb = df[\"response_B\"].astype(str).str.len().to_numpy().reshape(-1,1)\n        lp = df[\"prompt\"].astype(str).str.len().to_numpy().reshape(-1,1)\n        ldiff = la - lb\n        return np.hstack([d_abs, d_mul, la, lb, lp, ldiff]).astype(np.float32)\n    \n    X_tr = make_feats(Ep_tr, Ea_tr, Eb_tr, train)\n    X_te = make_feats(Ep_te, Ea_te, Eb_te, test)\n    y    = train[\"label\"].astype(int).values\n    print(f\"[feat] train {X_tr.shape}, test {X_te.shape}\")\n    \n    # (A) 전체 피처 스케일링 (길이/ldiff가 매우 커서 꼭 필요)\n    scaler = StandardScaler(with_mean=True, with_std=True)\n    X_tr = scaler.fit_transform(X_tr)\n    X_te = scaler.transform(X_te)\n    \n    # (선택) NaN 사전 점검\n    if np.isnan(X_tr).any() or np.isnan(X_te).any():\n        raise ValueError(\"NaN found in features after scaling\")\n    \n    # 3) 분류기\n    clf = SGDClassifier(\n        loss=\"log_loss\", max_iter=200, tol=1e-3,\n        early_stopping=True, n_iter_no_change=5,\n        average=True, random_state=cfg[\"random_state\"]\n    )\n    \n    X_tr1, X_val, y_tr, y_val = train_test_split(\n        X_tr, y, test_size=cfg[\"val_size\"], stratify=y, random_state=cfg[\"random_state\"]\n    )\n    clf.fit(X_tr1, y_tr)\n    \n    # (B) 항상 안전 확률 사용\n    vpred = _safe_proba_from_clf(clf, X_val, n_classes=3)\n    print(f\"[val] logloss={log_loss(y_val, vpred, labels=[0,1,2]):.4f}\")\n    \n    clf.fit(X_tr, y)\n    probs_3 = _safe_proba_from_clf(clf, X_te, n_classes=3)\n    \n    # 안전성 재확인\n    probs_3 = np.nan_to_num(probs_3, nan=1/3, posinf=1/3, neginf=0.0)\n    probs_3 = probs_3 / probs_3.sum(axis=1, keepdims=True)\n    \n    sub = pd.DataFrame({\n        \"id\": test[\"id\"].values,\n        \"winner_model_a\": probs_3[:,0],\n        \"winner_model_b\": probs_3[:,1],\n        \"winner_tie\":     probs_3[:,2],\n    })\n    s = sub[[\"winner_model_a\",\"winner_model_b\",\"winner_tie\"]].sum(1).to_numpy()\n    assert np.allclose(s, 1.0, atol=1e-6)\n    out_path = os.path.join(cfg[\"WORK_DIR\"], out_csv)\n    sub.to_csv(out_path, index=False)\n    print(f\"[save] {out_path}  total={time.time()-t0:.1f}s\")\n    print(sub.head())\n\nrun_step2_embed_fast(BASE_ARGS,model_path_or_name=BASE_ARGS[\"embed_model_dir\"],bs_embed=256,max_length=256,use_instruction=True, out_csv=\"submission.csv\")","metadata":{"id":"UPIwlxJt8nsY","trusted":true,"execution":{"iopub.status.busy":"2025-11-06T13:44:40.733252Z","iopub.execute_input":"2025-11-06T13:44:40.733600Z"}},"outputs":[{"name":"stdout","text":"[io] train:(57477, 9), test:(3, 4), submit:(3, 4)\n[pre/3way] shape: (57477, 10)  label counts: {0: 20064, 1: 19652, 2: 17761}\n","output_type":"stream"},{"name":"stderr","text":"2025-11-06 13:45:02.992369: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762436703.284028      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762436703.371555      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"[embed] sentence-transformers local: /kaggle/input/all-minilm-l6-v2/all-MiniLM-L6-v2\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[embed] all:   0%|                                                  | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba9f740a6a1f4a7f84c6b8754d18d531"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/225 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba44bc059c274295b213d8612ee87f0d"}},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":"##STEP3","metadata":{"id":"R-KxrWuD8rMN"}},{"cell_type":"code","source":"import os, time, torch, transformers\nfrom tqdm.auto import tqdm\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\nfrom peft import LoraConfig, get_peft_model\nfrom packaging.version import parse as V\nfrom sklearn.metrics import log_loss as _logloss\n\ndef _build_inputs_pair(df, tok):\n    sep = tok.sep_token or tok.eos_token or \"</s>\"\n    texts = []\n    for p, a, b in zip(df[\"prompt\"], df[\"response_A\"], df[\"response_B\"]):\n        s = f\"[INST] {p} [/INST] {sep} <A> {a} </A> {sep} <B> {b} </B>\"\n        texts.append(s)\n    return texts\n\ndef run_step3_lora_offline(\n    cfg: dict,\n    model_dir: str,\n    out_csv: str = \"submission_step3_lora.csv\",\n    batch_size: int = 8,\n    epochs: int = 4,\n    lr: float = 2e-5,\n    max_len: int = 512,\n):\n    t0_total = time.time()\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    print(f\"[lora/offline] device={device}, model_dir={model_dir}\")\n\n    # 1) 데이터\n    train, test, submit = load_csvs(cfg)\n    train = standardize_columns(train); test = standardize_columns(test)\n    train = build_label_threeway(train)\n    for col in [\"prompt\",\"response_A\",\"response_B\"]:\n        if col not in train.columns: train[col] = \"\"\n        if col not in test.columns:  test[col]  = \"\"\n\n    # 2) 토크나이저/모델\n    print(\"[init] loading tokenizer/model ...\")\n    tok  = AutoTokenizer.from_pretrained(model_dir, use_fast=True)\n    base = AutoModelForSequenceClassification.from_pretrained(model_dir, num_labels=3)\n    target_modules = [\"query_proj\",\"value_proj\"]\n    lcfg = LoraConfig(r=8, lora_alpha=16, target_modules=target_modules,\n                      lora_dropout=0.05, bias=\"none\", task_type=\"SEQ_CLS\")\n    model = get_peft_model(base, lcfg).to(device)\n\n    # 3) 입력 구성\n    print(\"[prep] building input pairs...\")\n    tr_texts = _build_inputs_pair(train, tok)\n    te_texts = _build_inputs_pair(test, tok)\n    labels   = train[\"label\"].astype(int).tolist()\n    \n    ds = Dataset.from_dict({\"text\": tr_texts, \"label\": labels})\n    \n    def preprocess(batch):\n        enc = tok(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=max_len)\n        enc[\"labels\"] = batch[\"label\"]  # 분류 레이블\n        return enc\n    \n    # batched + tqdm 진행률 + 빠른 배치 사이즈\n    tok_ds = ds.map(\n        preprocess,\n        batched=True,\n        batch_size=1024,\n        remove_columns=[\"text\", \"label\"],\n        desc=\"Tokenizing (batched)\"\n    )\n    \n    split = tok_ds.train_test_split(test_size=cfg[\"val_size\"], seed=cfg[\"random_state\"])\n\n    # 4) TrainingArguments (버전 호환: 오래된 버전은 evaluation_strategy 미지원)\n    import inspect\n    \n    base_kwargs = dict(\n        output_dir=cfg[\"WORK_DIR\"],\n        per_device_train_batch_size=batch_size,\n        per_device_eval_batch_size=batch_size,\n        num_train_epochs=epochs,\n        learning_rate=lr,\n        logging_dir=f\"{cfg['WORK_DIR']}/logs\",\n        report_to=\"none\",\n    )\n    \n    sig = inspect.signature(TrainingArguments.__init__)\n    params = sig.parameters\n    \n    if \"evaluation_strategy\" in params:\n        # ✅ 최신 스타일 (transformers 4.10+ 등)\n        args_tr = TrainingArguments(\n            **base_kwargs,\n            logging_strategy=\"steps\",\n            logging_steps=50,\n            evaluation_strategy=\"epoch\",\n            save_strategy=\"epoch\",\n            load_best_model_at_end=True,\n            metric_for_best_model=\"eval_log_loss\",\n            greater_is_better=False, \n            save_total_limit=1,\n        )\n    else:\n        # ✅ 레거시 스타일 (evaluation_strategy 미지원)\n        #   - evaluate_during_training이 있는 구버전용 처리\n        legacy_extra = {}\n        if \"evaluate_during_training\" in params:\n            legacy_extra[\"evaluate_during_training\"] = True\n        if \"logging_steps\" in params:\n            legacy_extra[\"logging_steps\"] = 50\n        if \"save_steps\" in params:\n            legacy_extra[\"save_steps\"] = 500\n        # 일부 구버전에선 load_best_model_at_end/metric_for_best_model도 미지원이므로 생략\n        args_tr = TrainingArguments(\n            **base_kwargs,\n            **legacy_extra\n        )\n        \n    # 5) metrics\n    def compute_metrics(eval_pred):\n        logits, lab = eval_pred\n        probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()  # (N,3)\n        return {\"log_loss\": _logloss(lab, probs, labels=[0,1,2])}    # ← labels 지정\n\n    print(\"[train] starting training ...\")\n    trainer = Trainer(\n        model=model,\n        args=args_tr,\n        train_dataset=split[\"train\"],\n        eval_dataset=split[\"test\"],\n        tokenizer=tok,\n        compute_metrics=compute_metrics,\n    )\n\n    trainer.train()\n    print(f\"[train] finished in {time.time()-t0_total:.1f}s\")\n\n    # 6) 추론 (진행률/시간)\n    print(\"[infer] predicting test set ...\")\n    all_probs = []\n    with torch.no_grad():\n        for i in tqdm(range(0, len(te_texts), batch_size), desc=\"Inference\", ncols=90):\n            batch = te_texts[i:i+batch_size]\n            te_enc = tok(batch, truncation=True, padding=\"max_length\",\n                         max_length=max_len, return_tensors=\"pt\").to(device)\n            logits = model(**te_enc).logits\n            probs3 = torch.softmax(logits, dim=-1).cpu().numpy()       # (B, 3)\n            all_probs.append(probs3)\n\n    probs_3 = np.vstack(all_probs)  \n    probs_3 = np.clip(probs_3, 1e-7, 1-1e-7)\n    probs_3 = probs_3 / probs_3.sum(axis=1, keepdims=True)     \n\n    # test.csv id 순서에 맞춰 DataFrame 구성\n    submit3 = pd.DataFrame({\n        \"id\": test[\"id\"].values,\n        \"winner_model_a\": probs_3[:, 0],\n        \"winner_model_b\": probs_3[:, 1],\n        \"winner_tie\":     probs_3[:, 2],\n    })\n    sums = submit3[[\"winner_model_a\",\"winner_model_b\",\"winner_tie\"]].sum(1)\n    assert np.allclose(sums, 1.0, atol=1e-6)\n\n    out_path = os.path.join(cfg[\"WORK_DIR\"], out_csv)  # 예: submission.csv\n    submit3.to_csv(out_path, index=False)\n    print(\"[save]\", out_path)\n    print(submit3.head())\n    print(\"sum(min,max) =\", float(sums.min()), float(sums.max()))\n    print(f\"✅ Done in {time.time()-t0_total:.1f}s total\")\n'''\nrun_step3_lora_offline(\n    BASE_ARGS,\n    model_dir=DEBERTA_DIR,              # 위에서 입력한 경로\n    out_csv=\"submission.csv\",\n    batch_size=8, epochs=1, lr=2e-5, max_len=512,\n)'''","metadata":{"id":"9F1KR7KQ8uPI","trusted":true,"execution":{"iopub.status.busy":"2025-11-06T08:14:39.241170Z","iopub.execute_input":"2025-11-06T08:14:39.241555Z","iopub.status.idle":"2025-11-06T08:15:04.379135Z","shell.execute_reply.started":"2025-11-06T08:14:39.241508Z","shell.execute_reply":"2025-11-06T08:15:04.378401Z"}},"outputs":[{"name":"stderr","text":"2025-11-06 08:14:50.722262: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762416890.963109      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762416891.023854      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'\\nrun_step3_lora_offline(\\n    BASE_ARGS,\\n    model_dir=DEBERTA_DIR,              # 위에서 입력한 경로\\n    out_csv=\"submission.csv\",\\n    batch_size=8, epochs=1, lr=2e-5, max_len=512,\\n)'"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"### Final Model","metadata":{}},{"cell_type":"code","source":"import os, time, torch, transformers\nfrom tqdm.auto import tqdm\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\nfrom transformers import TrainerCallback, TrainerControl, TrainerState\nfrom peft import LoraConfig, get_peft_model\nfrom packaging.version import parse as V\n\n# [FIX: v5 호환 + 추론에 필요한 import 누락 보완]\nimport numpy as np\nimport pandas as pd\nimport inspect\nfrom typing import Optional\n\ndef _build_inputs_pair(df, tok):\n    sep = tok.sep_token or tok.eos_token or \"</s>\"\n    texts = []\n    for p, a, b in zip(df[\"prompt\"], df[\"response_A\"], df[\"response_B\"]):\n        s = f\"[INST] {p} [/INST] {sep} <A> {a} </A> {sep} <B> {b} </B>\"\n        texts.append(s)\n    return texts\n\ndef _reinit_classification_head(model: torch.nn.Module):\n    # (동일) 분류헤드 재초기화\n    head = None\n    if hasattr(model, \"classifier\") and isinstance(model.classifier, torch.nn.Linear):\n        head = model.classifier\n    elif hasattr(model, \"score\") and isinstance(model.score, torch.nn.Linear):\n        head = model.score\n    elif hasattr(model, \"base_model\") and hasattr(model.base_model, \"classifier\") and isinstance(model.base_model.classifier, torch.nn.Linear):\n        head = model.base_model.classifier\n    if head is not None:\n        torch.nn.init.xavier_uniform_(head.weight)\n        if head.bias is not None:\n            torch.nn.init.zeros_(head.bias)\n\nclass SimpleEarlyStopper(TrainerCallback):\n    def __init__(self, metric_key=\"eval_log_loss\", patience=2, minimize=True, eps=0.0):\n        self.metric_key, self.patience, self.minimize, self.eps = metric_key, patience, minimize, eps\n        self.best = None\n        self.bad = 0\n    def on_evaluate(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kw):\n        m = kw.get(\"metrics\", {})\n        if self.metric_key not in m: return control\n        curr = m[self.metric_key]\n        if self.best is None:\n            self.best, self.bad = curr, 0\n        else:\n            improved = (curr < self.best - self.eps) if self.minimize else (curr > self.best + self.eps)\n            if improved: self.best, self.bad = curr, 0\n            else:\n                self.bad += 1\n                if self.bad >= self.patience:\n                    control.should_training_stop = True\n        return control\n\ndef run_step3_lora_offline(\n    cfg: dict,\n    model_dir: str,\n    out_csv: str = \"submission_step3_lora.csv\",\n    batch_size: int = 8,\n    epochs: int = 4,\n    lr: float = 2e-5,\n    max_len: int = 512,\n    # 안정화 하이퍼파라미터(기존)\n    warmup_ratio: float = 0.1,\n    weight_decay: float = 0.01,\n    max_grad_norm: float = 1.0,\n    label_smoothing: float = 0.1,\n    early_stopping_patience: int = 2,\n    seed: int = 42,\n    scheduler_type: str = \"cosine\",\n):\n    t0_total = time.time()\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    print(f\"[lora/offline] device={device}, model_dir={model_dir}\")\n\n    # 시드 및 matmul precision\n    try:\n        torch.manual_seed(seed); np.random.seed(seed)\n        if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n        torch.set_float32_matmul_precision(\"medium\")\n    except Exception as e:\n        print(\"[warn] seed/matmul:\", e)\n\n    # 1) 데이터\n    train, test, submit = load_csvs(cfg)\n    train = standardize_columns(train); test = standardize_columns(test)\n    train = build_label_threeway(train)\n    for col in [\"prompt\",\"response_A\",\"response_B\"]:\n        if col not in train.columns: train[col] = \"\"\n        if col not in test.columns:  test[col]  = \"\"\n\n    # 2) 토크나이저/모델\n    print(\"[init] loading tokenizer/model ...\")\n    tok  = AutoTokenizer.from_pretrained(model_dir, use_fast=True)\n    base = AutoModelForSequenceClassification.from_pretrained(model_dir, num_labels=3)\n    _reinit_classification_head(base)  # 분류헤드 재초기화\n\n    target_modules = [\"query_proj\",\"value_proj\"]\n    lcfg = LoraConfig(r=8, lora_alpha=16, target_modules=target_modules,\n                      lora_dropout=0.05, bias=\"none\", task_type=\"SEQ_CLS\")\n    model = get_peft_model(base, lcfg).to(device)\n    try: model.print_trainable_parameters()\n    except: pass\n\n    # 3) 입력 구성\n    print(\"[prep] building input pairs...\")\n    tr_texts = _build_inputs_pair(train, tok)\n    te_texts = _build_inputs_pair(test, tok)\n    labels   = train[\"label\"].astype(int).tolist()\n    ds = Dataset.from_dict({\"text\": tr_texts, \"label\": labels})\n    def preprocess(batch):\n        enc = tok(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=max_len)\n        enc[\"labels\"] = batch[\"label\"]\n        return enc\n    tok_ds = ds.map(preprocess, batched=True, batch_size=1024, remove_columns=[\"text\",\"label\"],\n                    desc=\"Tokenizing (batched)\")\n    split = tok_ds.train_test_split(test_size=cfg[\"val_size\"], seed=cfg[\"random_state\"])\n\n    # 4) TrainingArguments (버전 호환 강화)\n    sig = inspect.signature(TrainingArguments.__init__)\n    params = sig.parameters\n    def _has_arg(n: str) -> bool: return n in params\n\n    base_kwargs = dict(\n        output_dir=cfg[\"WORK_DIR\"],\n        per_device_train_batch_size=batch_size,\n        per_device_eval_batch_size=batch_size,\n        num_train_epochs=epochs,\n        learning_rate=lr,\n        logging_dir=f\"{cfg['WORK_DIR']}/logs\",\n        report_to=\"none\",\n        seed=seed,\n        remove_unused_columns=False,\n    )\n\n    stable_kwargs = {}\n    if _has_arg(\"lr_scheduler_type\"):     stable_kwargs[\"lr_scheduler_type\"] = scheduler_type\n    if _has_arg(\"warmup_ratio\"):          stable_kwargs[\"warmup_ratio\"] = warmup_ratio\n    if _has_arg(\"weight_decay\"):          stable_kwargs[\"weight_decay\"] = weight_decay\n    if _has_arg(\"max_grad_norm\"):         stable_kwargs[\"max_grad_norm\"] = max_grad_norm\n    if _has_arg(\"label_smoothing_factor\"):stable_kwargs[\"label_smoothing_factor\"] = label_smoothing\n    if torch.cuda.is_available():\n        if _has_arg(\"bf16\") and torch.cuda.get_device_capability(0)[0] >= 8:\n            stable_kwargs[\"bf16\"] = True\n        elif _has_arg(\"fp16\"):\n            stable_kwargs[\"fp16\"] = True\n\n    # [FIX: 얼리 스톱핑이 요구하는 필드 지원 여부 개별 점검]\n    can_load_best = _has_arg(\"load_best_model_at_end\")\n    can_metric    = _has_arg(\"metric_for_best_model\")\n    can_greater   = _has_arg(\"greater_is_better\")\n\n    extra_eval_kwargs = {}\n    if \"evaluation_strategy\" in params:\n        extra_eval_kwargs[\"evaluation_strategy\"] = \"epoch\"\n        if _has_arg(\"save_strategy\"): extra_eval_kwargs[\"save_strategy\"] = \"epoch\"\n        if can_load_best: extra_eval_kwargs[\"load_best_model_at_end\"] = True  # 요구됨\n        if can_metric:    extra_eval_kwargs[\"metric_for_best_model\"] = \"eval_log_loss\"\n        if can_greater:   extra_eval_kwargs[\"greater_is_better\"] = False\n        if _has_arg(\"save_total_limit\"): extra_eval_kwargs[\"save_total_limit\"] = 1\n        if _has_arg(\"logging_strategy\"): extra_eval_kwargs[\"logging_strategy\"] = \"steps\"\n        if _has_arg(\"logging_steps\"):    extra_eval_kwargs[\"logging_steps\"] = 50\n        if _has_arg(\"optim\"):            extra_eval_kwargs[\"optim\"] = \"adamw_torch\"\n    else:\n        # 레거시 대응\n        if _has_arg(\"evaluate_during_training\"): extra_eval_kwargs[\"evaluate_during_training\"] = True\n        if _has_arg(\"logging_steps\"):            extra_eval_kwargs[\"logging_steps\"] = 50\n        if _has_arg(\"save_steps\"):               extra_eval_kwargs[\"save_steps\"] = 500\n        # 이 경우 load_best/metric 지원이 없을 수 있으므로 EarlyStopping 비활성화 예정\n\n    args_tr = TrainingArguments(**base_kwargs, **stable_kwargs, **extra_eval_kwargs)\n\n    # 5) metrics\n    def compute_metrics(eval_pred):\n        logits, lab = eval_pred\n        probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n        return {\"log_loss\": _logloss(lab, probs, labels=[0,1,2])}\n\n    # [FIX] Trainer 시그니처를 확인해서 **지원되는 인자만** 전달\n    trainer_sig_keys = set(inspect.signature(Trainer.__init__).parameters.keys())\n\n    trainer_kwargs = {\n        \"model\": model,\n        \"args\": args_tr,\n        \"train_dataset\": split[\"train\"],\n        \"eval_dataset\": split[\"test\"],\n        \"compute_metrics\": compute_metrics,\n    }\n\n    # [FIX] v5 권장: processing_class가 있으면 사용, 아니면 tokenizer 사용\n    if \"processing_class\" in trainer_sig_keys:\n        trainer_kwargs[\"processing_class\"] = tok   # [FIX]\n    elif \"tokenizer\" in trainer_sig_keys:\n        trainer_kwargs[\"tokenizer\"] = tok          # [fallback]\n\n    # [FIX] label_names는 버전에 따라 __init__ 인자가 아님 → 있으면만 넣기\n    if \"label_names\" in trainer_sig_keys:\n        trainer_kwargs[\"label_names\"] = [\"labels\"]  # [FIX] Peft 경고 방지\n\n    # [FIX] 콜백은 지원할 때만\n    callbacks = []\n    try:\n        from transformers import EarlyStoppingCallback\n        if getattr(args_tr, \"metric_for_best_model\", None) and getattr(args_tr, \"load_best_model_at_end\", False):\n            callbacks.append(EarlyStoppingCallback(\n                early_stopping_patience=early_stopping_patience,\n                early_stopping_threshold=0.0\n            ))\n        else:\n            print(\"[info] EarlyStoppingCallback skipped (metric_for_best_model/load_best_model_at_end 미지원/비활성).\")\n    except Exception as e:\n        print(\"[warn] EarlyStoppingCallback not available:\", e)\n\n    if callbacks and \"callbacks\" in trainer_sig_keys:\n        trainer_kwargs[\"callbacks\"] = callbacks     # [FIX]\n\n    print(\"[train] starting training ...\")\n    trainer = Trainer(**trainer_kwargs)\n    trainer.add_callback(SimpleEarlyStopper(metric_key=\"eval_log_loss\", patience=2, minimize=True))\n\n    # [FIX] __init__에서 label_names 인자를 못 받는 버전 대비:\n    #       속성이 있으면 직접 주입해서 경고 억제 (없으면 무시)\n    if hasattr(trainer, \"label_names\") and not getattr(trainer, \"label_names\"):\n        trainer.label_names = [\"labels\"]            # [FIX]\n\n    trainer.train()\n    print(f\"[train] finished in {time.time()-t0_total:.1f}s\")\n\n    # 6) 추론\n    print(\"[infer] predicting test set ...\")\n    model.eval()\n    all_probs = []\n    with torch.no_grad():\n        for i in tqdm(range(0, len(te_texts), batch_size), desc=\"Inference\", ncols=90):\n            batch = te_texts[i:i+batch_size]\n            te_enc = tok(batch, truncation=True, padding=\"max_length\",\n                         max_length=max_len, return_tensors=\"pt\").to(device)\n            logits = model(**te_enc).logits\n            probs3 = torch.softmax(logits, dim=-1).cpu().numpy()\n            all_probs.append(probs3)\n\n    probs_3 = np.vstack(all_probs)\n    probs_3 = np.clip(probs_3, 1e-7, 1-1e-7)\n    probs_3 = probs_3 / probs_3.sum(axis=1, keepdims=True)\n\n    submit3 = pd.DataFrame({\n        \"id\": test[\"id\"].values,\n        \"winner_model_a\": probs_3[:, 0],\n        \"winner_model_b\": probs_3[:, 1],\n        \"winner_tie\":     probs_3[:, 2],\n    })\n    sums = submit3[[\"winner_model_a\",\"winner_model_b\",\"winner_tie\"]].sum(1)\n    assert np.allclose(sums, 1.0, atol=1e-6)\n\n    out_path = os.path.join(cfg[\"WORK_DIR\"], out_csv)\n    submit3.to_csv(out_path, index=False)\n    print(\"[save]\", out_path)\n    print(submit3.head())\n    print(\"sum(min,max) =\", float(sums.min()), float(sums.max()))\n    print(f\"✅ Done in {time.time()-t0_total:.1f}s total\")\n\nrun_step3_lora_offline(\n    BASE_ARGS,\n    model_dir=DEBERTA_DIR,\n    out_csv=\"submission.csv\",\n    batch_size=8,\n    epochs=6,\n    lr=2e-5,\n    max_len=512,\n    warmup_ratio=0.1,\n    weight_decay=0.01,\n    max_grad_norm=1.0,\n    label_smoothing=0.02,\n    early_stopping_patience=2,\n    scheduler_type=\"cosine\",\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T08:15:04.380046Z","iopub.execute_input":"2025-11-06T08:15:04.380644Z","iopub.status.idle":"2025-11-06T08:15:04.415359Z","shell.execute_reply.started":"2025-11-06T08:15:04.380626Z","shell.execute_reply":"2025-11-06T08:15:04.414796Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'\\nrun_step3_lora_offline(\\n    BASE_ARGS,\\n    model_dir=DEBERTA_DIR,\\n    out_csv=\"submission.csv\",\\n    batch_size=8,\\n    epochs=6,\\n    lr=2e-5,\\n    max_len=512,\\n    warmup_ratio=0.1,\\n    weight_decay=0.01,\\n    max_grad_norm=1.0,\\n    label_smoothing=0.02,\\n    early_stopping_patience=2,\\n    scheduler_type=\"cosine\",\\n)\\n'"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"import os, sys, json, math, random, time\nimport numpy as np, pandas as pd\nfrom typing import Dict, Tuple, Optional, List\nfrom tqdm.auto import tqdm\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\nfrom transformers import (\n    AutoTokenizer,\n    AutoConfig,\n    AutoModelForSequenceClassification,\n    get_cosine_schedule_with_warmup,\n)\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\n\n\n# ==== Utils ====\ndef seed_everything(seed=42):\n    random.seed(seed); np.random.seed(seed)\n    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n\ndef count_trainable_params(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n# ==== Dataset ====\nclass Pairwise3ClsDataset(Dataset):\n    \"\"\"\n    입력: prompt, response_A, response_B → 3-class(0:A, 1:B, 2:tie)\n    텍스트 포맷: [CLS] prompt [SEP] A [SEP] B\n    \"\"\"\n    def __init__(self, df: pd.DataFrame, tokenizer, max_len: int = 384, has_label: bool = True):\n        self.df = df.reset_index(drop=True)\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.has_label = has_label\n\n        # 컬럼 이름 표준화(안전)\n        self.df = standardize_columns(self.df)\n\n        need_cols = [\"response_A\", \"response_B\", \"prompt\"]\n        for c in need_cols:\n            if c not in self.df.columns:\n                raise ValueError(f\"Missing column: {c}\")\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        prompt = str(row.get(\"prompt\", \"\")) or \"\"\n        a = str(row[\"response_A\"])\n        b = str(row[\"response_B\"])\n\n        # 텍스트 구성\n        # DeBERTa도 sep_token 사용 가능\n        sep = self.tokenizer.sep_token or \"[SEP]\"\n        text = f\"{prompt} {sep} [Response A] {a} {sep} [Response B] {b}\"\n\n        item = {\"text\": text}\n        if self.has_label:\n            label = int(row[\"label\"])\n            item[\"label\"] = label\n        else:\n            item[\"id\"] = row[\"id\"]\n        return item\n\ndef collate_fn_train(batch, tokenizer, max_len):\n    texts = [b[\"text\"] for b in batch]\n    enc = tokenizer(\n        texts,\n        padding=True,\n        truncation=True,\n        max_length=max_len,\n        return_tensors=\"pt\"\n    )\n    labels = torch.tensor([b[\"label\"] for b in batch], dtype=torch.long)\n    return enc, labels\n\ndef collate_fn_test(batch, tokenizer, max_len):\n    texts = [b[\"text\"] for b in batch]\n    ids = [b[\"id\"] for b in batch]\n    enc = tokenizer(\n        texts,\n        padding=True,\n        truncation=True,\n        max_length=max_len,\n        return_tensors=\"pt\"\n    )\n    return enc, ids\n\n# ==== Training / Eval Routines ====\ndef get_optimizer(model, lr=2e-5, weight_decay=0.01):\n    no_decay = [\"bias\", \"LayerNorm.weight\", \"layer_norm.weight\"]\n    param_groups = [\n        {\n            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n            \"weight_decay\": weight_decay,\n        },\n        {\n            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n            \"weight_decay\": 0.0,\n        },\n    ]\n    return torch.optim.AdamW(param_groups, lr=lr)\n\n@torch.no_grad()\ndef evaluate(model, val_loader, device, label_smoothing=0.0, return_preds=False):\n    model.eval()\n    ce = nn.CrossEntropyLoss(label_smoothing=label_smoothing, reduction=\"mean\")\n    all_probs, all_labels = [], []\n    total_loss = 0.0\n\n    for enc, labels in val_loader:\n        for k in enc:\n            enc[k] = enc[k].to(device, non_blocking=True)\n        labels = labels.to(device, non_blocking=True)\n        logits = model(**enc).logits\n        loss = ce(logits, labels)\n        total_loss += loss.item() * labels.size(0)\n\n        probs = torch.softmax(logits, dim=-1).cpu().numpy()\n        all_probs.append(probs)\n        all_labels.append(labels.cpu().numpy())\n\n    all_probs = np.concatenate(all_probs, axis=0)\n    all_labels = np.concatenate(all_labels, axis=0)\n    preds = np.argmax(all_probs, axis=1)\n\n    val_logloss = log_loss(all_labels, all_probs, labels=[0,1,2])\n    avg_loss = total_loss / len(val_loader.dataset)\n\n    if return_preds:\n        return avg_loss, val_logloss, all_probs, preds, all_labels\n    return avg_loss, val_logloss, all_probs\n\ndef train_one_epoch(model, train_loader, optimizer, scheduler, device, scaler, grad_accum_steps=1, max_grad_norm=1.0, label_smoothing=0.0):\n    model.train()\n    ce = nn.CrossEntropyLoss(label_smoothing=label_smoothing, reduction=\"mean\")\n\n    running_loss = 0.0\n    optimizer.zero_grad(set_to_none=True)\n\n    for step, (enc, labels) in enumerate(train_loader):\n        for k in enc:\n            enc[k] = enc[k].to(device, non_blocking=True)\n        labels = labels.to(device, non_blocking=True)\n\n        with torch.cuda.amp.autocast(enabled=scaler is not None):\n            outputs = model(**enc)\n            logits = outputs.logits\n            loss = ce(logits, labels) / grad_accum_steps\n\n        if scaler is not None:\n            scaler.scale(loss).backward()\n        else:\n            loss.backward()\n\n        if (step + 1) % grad_accum_steps == 0:\n            if scaler is not None:\n                scaler.unscale_(optimizer)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n                optimizer.step()\n            optimizer.zero_grad(set_to_none=True)\n            if scheduler is not None:\n                scheduler.step()\n\n        running_loss += loss.item() * grad_accum_steps\n\n    return running_loss / len(train_loader)\n\n# ==== Main Runner ====\ndef run_full_finetune(cfg: Dict):\n    seed_everything(cfg.get(\"random_state\", 42))\n\n    # I/O\n    train_df, test_df, submit_df = load_csvs(cfg)\n    train_df = standardize_columns(train_df)\n    test_df  = standardize_columns(test_df)\n\n    # 라벨 생성(0:A, 1:B, 2:tie)\n    train_df = build_label_threeway(train_df)\n\n    # Split\n    trn, val = train_test_split(\n        train_df,\n        test_size=cfg.get(\"val_size\", 0.2),\n        random_state=cfg.get(\"random_state\", 42),\n        stratify=train_df[\"label\"]\n    )\n    trn = trn.reset_index(drop=True)\n    val = val.reset_index(drop=True)\n\n    # Tokenizer / Model\n    model_name_or_path = cfg.get(\"model_dir\", DEBERTA_DIR)\n    num_labels = 3\n    max_len = cfg.get(\"max_len\", 384)\n\n    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n    config = AutoConfig.from_pretrained(\n        model_name_or_path,\n        num_labels=num_labels,\n        problem_type=\"single_label_classification\",\n        hidden_dropout_prob=0.2,          \n        attention_probs_dropout_prob=0.1, \n        classifier_dropout=0.2            \n    )\n    model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, config=config)\n\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    model.to(device)\n\n    # Dataset / Loader\n    train_ds = Pairwise3ClsDataset(trn, tokenizer, max_len=max_len, has_label=True)\n    val_ds   = Pairwise3ClsDataset(val, tokenizer, max_len=max_len, has_label=True)\n    test_ds  = Pairwise3ClsDataset(test_df, tokenizer, max_len=max_len, has_label=False)\n\n    train_bs = cfg.get(\"train_batch_size\", 8)\n    val_bs   = cfg.get(\"valid_batch_size\", 16)\n    test_bs  = cfg.get(\"test_batch_size\", 16)\n\n    train_loader = DataLoader(train_ds, batch_size=train_bs, shuffle=True, num_workers=2,\n                              pin_memory=True, collate_fn=lambda b: collate_fn_train(b, tokenizer, max_len))\n    val_loader   = DataLoader(val_ds, batch_size=val_bs, shuffle=False, num_workers=2,\n                              pin_memory=True, collate_fn=lambda b: collate_fn_train(b, tokenizer, max_len))\n    test_loader  = DataLoader(test_ds, batch_size=test_bs, shuffle=False, num_workers=2,\n                              pin_memory=True, collate_fn=lambda b: collate_fn_test(b, tokenizer, max_len))\n\n    # Optim / Sched\n    lr = cfg.get(\"lr\", 2e-5)\n    epochs = cfg.get(\"epochs\", 5)\n    grad_accum = cfg.get(\"grad_accum_steps\", 1)\n    warmup_ratio = cfg.get(\"warmup_ratio\", 0.1)\n    max_grad_norm = cfg.get(\"max_grad_norm\", 1.0)\n    label_smoothing = cfg.get(\"label_smoothing\", 0.05)\n\n    total_steps = math.ceil(len(train_loader) / grad_accum) * epochs\n    warmup_steps = int(total_steps * warmup_ratio)\n\n    optimizer = get_optimizer(model, lr=lr, weight_decay=cfg.get(\"weight_decay\", 0.01))\n    scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n\n    # AMP\n    scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n\n    # Early Stopping & Checkpoint\n    patience = cfg.get(\"patience\", 2)\n    best_val_logloss = 1e9\n    best_path = os.path.join(cfg[\"WORK_DIR\"], \"deberta3_small_fullFT_best.pt\")\n    no_improve = 0\n\n    print(f\"[init] Trainable params: {count_trainable_params(model):,}\")\n    print(f\"[sched] total_steps={total_steps}, warmup_steps={warmup_steps}\")\n    print(f\"[hp] epochs={epochs}, bs={train_bs}, accum={grad_accum}, lr={lr}, label_smoothing={label_smoothing}\")\n\n    for ep in range(1, epochs + 1):\n        t0 = time.time()\n        tr_loss = train_one_epoch(\n            model, train_loader, optimizer, scheduler, device, scaler,\n            grad_accum_steps=grad_accum, max_grad_norm=max_grad_norm, label_smoothing=label_smoothing\n        )\n        val_loss, val_logloss, _ = evaluate(model, val_loader, device, label_smoothing=label_smoothing)\n        dt = time.time() - t0\n        print(f\"[epoch {ep}/{epochs}] train_loss={tr_loss:.4f}  val_loss={val_loss:.4f}  val_logloss={val_logloss:.5f}  ({dt:.1f}s)\")\n\n        if val_logloss < best_val_logloss - 1e-6:\n            best_val_logloss = val_logloss\n            torch.save({\"model_state\": model.state_dict(), \"config\": config.to_dict()}, best_path)\n            print(f\"  -> New best! saved: {best_path}\")\n            no_improve = 0\n        else:\n            no_improve += 1\n            if no_improve >= patience:\n                print(f\"  -> Early stopping (patience={patience})\")\n                break\n\n    # Load best\n    if os.path.exists(best_path):\n        state = torch.load(best_path, map_location=\"cpu\")\n        model.load_state_dict(state[\"model_state\"])\n        model.to(device)\n        print(f\"[load] best checkpoint (val_logloss={best_val_logloss:.5f})\")\n\n        # ---------- Validation analysis: Confusion Matrix & Misclassified ----------\n    val_loss, val_logloss, val_probs, val_preds, val_labels = evaluate(\n        model, val_loader, device, label_smoothing=label_smoothing, return_preds=True\n    )\n    label_names = [\"A win\",\"B win\",\"Tie\"]\n\n    # Confusion Matrix (표시 + 저장)\n    cm = confusion_matrix(val_labels, val_preds, labels=[0,1,2])\n\n    plt.figure(figsize=(5.5, 4.5))\n    plt.imshow(cm, interpolation=\"nearest\")\n    plt.title(\"Confusion Matrix (Validation)\")\n    plt.colorbar()\n    tick_marks = np.arange(len(label_names))\n    plt.xticks(tick_marks, label_names, rotation=0)\n    plt.yticks(tick_marks, label_names)\n    # 숫자 표시\n    thresh = cm.max() / 2.0 if cm.size else 0\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            plt.text(j, i, format(cm[i, j], \"d\"),\n                     ha=\"center\", va=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.ylabel(\"True\")\n    plt.xlabel(\"Predicted\")\n    plt.tight_layout()\n    cm_path = os.path.join(cfg[\"WORK_DIR\"], \"confusion_matrix_val.png\")\n    plt.savefig(cm_path, dpi=150)\n    plt.show()\n    print(f\"[viz] confusion matrix saved to: {cm_path}\")\n\n    # Classification Report (콘솔)\n    print(classification_report(val_labels, val_preds, target_names=label_names, digits=4))\n\n    # Misclassified 샘플 정리(+ 저장)\n    wrong_idx = np.where(val_preds != val_labels)[0]\n    print(f\"[analysis] misclassified: {len(wrong_idx)} / {len(val_labels)}\")\n\n    # val 데이터프레임에서 해당 행 매칭\n    # (val_loader 순서 = val.reset_index(drop=True) 기반이므로 인덱스 align)\n    val_reset = val.reset_index(drop=True).copy()\n    mis_df = val_reset.iloc[wrong_idx].copy()\n    mis_df[\"true_label\"] = [label_names[i] for i in val_labels[wrong_idx]]\n    mis_df[\"pred_label\"] = [label_names[i] for i in val_preds[wrong_idx]]\n    mis_df[\"p_A\"] = val_probs[wrong_idx, 0]\n    mis_df[\"p_B\"] = val_probs[wrong_idx, 1]\n    mis_df[\"p_Tie\"] = val_probs[wrong_idx, 2]\n\n    mis_path = os.path.join(cfg[\"WORK_DIR\"], \"misclassified_val.csv\")\n    cols = [\"prompt\",\"response_A\",\"response_B\",\"true_label\",\"pred_label\",\"p_A\",\"p_B\",\"p_Tie\"]\n    # 존재하는 컬럼만 저장(안전)\n    cols = [c for c in cols if c in mis_df.columns]\n    mis_df.to_csv(mis_path, index=False, columns=cols)\n    print(f\"[save] misclassified samples saved to: {mis_path}\")\n\n    # 콘솔에 샘플 몇 개만 보기\n    show_n = min(5, len(wrong_idx))\n    for i in range(show_n):\n        ridx = wrong_idx[i]\n        row = val_reset.iloc[ridx]\n        print(\"=\"*80)\n        print(f\"[Prompt]\\n{row.get('prompt','')}\\n\")\n        print(f\"[Response A]\\n{row.get('response_A','')[:500]}...\\n\")\n        print(f\"[Response B]\\n{row.get('response_B','')[:500]}...\\n\")\n        print(f\"✅ True: {label_names[val_labels[ridx]]} | ❌ Pred: {label_names[val_preds[ridx]]} | \"\n              f\"p=[A:{val_probs[ridx,0]:.3f}, B:{val_probs[ridx,1]:.3f}, Tie:{val_probs[ridx,2]:.3f}]\")\n\n    # Inference on test\n    model.eval()\n    all_probs = []\n    all_ids = []\n    with torch.no_grad():\n        for enc, ids in test_loader:\n            for k in enc:\n                enc[k] = enc[k].to(device, non_blocking=True)\n            logits = model(**enc).logits\n            probs = torch.softmax(logits, dim=-1).cpu().numpy()\n            all_probs.append(probs)\n            all_ids.extend(ids)\n    all_probs = np.concatenate(all_probs, axis=0)\n\n    # Save submission\n    out_csv = os.path.join(cfg[\"WORK_DIR\"], \"submission.csv\")\n    test_df_sorted = test_df.copy()\n    # test_df에 id가 반드시 있다고 가정\n    # 혹시 정렬이 섞였을 수 있으니 all_ids 순서대로 데이터프레임 맞추기\n    test_df_sorted = test_df.set_index(\"id\").loc[all_ids].reset_index()\n    save_submission_threecols(test_df_sorted, all_probs, out_csv)\n    print(\"[done]\")\n\n# ==== 실행 ====\nCFG = {\n    **BASE_ARGS,\n    # 모델/학습 하이퍼파라미터\n    \"model_dir\": DEBERTA_DIR,\n    \"max_len\": 384,\n    \"train_batch_size\": 8,     # VRAM 여유에 따라 8~16 권장\n    \"valid_batch_size\": 16,\n    \"test_batch_size\": 16,\n    \"epochs\": 5,               # 4~6 범위 권장\n    \"lr\": 1.2e-5,                # 1e-5 ~ 3e-5 사이 권장\n    \"weight_decay\": 0.03,\n    \"grad_accum_steps\": 1,     # VRAM 모자라면 2~4로\n    \"warmup_ratio\": 0.06,\n    \"max_grad_norm\": 1.0,\n    \"label_smoothing\": 0.08,   # 0.0~0.1 사이에서 조절\n    \"patience\": 2,             # early stopping\n}\n\nrun_full_finetune(CFG)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T08:15:04.416470Z","iopub.execute_input":"2025-11-06T08:15:04.416739Z","iopub.status.idle":"2025-11-06T10:13:09.955260Z","shell.execute_reply.started":"2025-11-06T08:15:04.416723Z","shell.execute_reply":"2025-11-06T10:13:09.954265Z"}},"outputs":[{"name":"stdout","text":"[io] train:(57477, 9), test:(3, 4), submit:(3, 4)\n[pre/3way] shape: (57477, 10)  label counts: {0: 20064, 1: 19652, 2: 17761}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\nSome weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/deberta-v3-small-local and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"[init] Trainable params: 141,897,219\n[sched] total_steps=28740, warmup_steps=1724\n[hp] epochs=5, bs=8, accum=1, lr=1.2e-05, label_smoothing=0.08\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_37/800329554.py:251: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n/tmp/ipykernel_37/800329554.py:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=scaler is not None):\n","output_type":"stream"},{"name":"stdout","text":"[epoch 1/5] train_loss=1.0945  val_loss=1.0842  val_logloss=1.08162  (1370.6s)\n  -> New best! saved: /kaggle/working/deberta3_small_fullFT_best.pt\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_37/800329554.py:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=scaler is not None):\n","output_type":"stream"},{"name":"stdout","text":"[epoch 2/5] train_loss=1.0794  val_loss=1.0729  val_logloss=1.06605  (1371.1s)\n  -> New best! saved: /kaggle/working/deberta3_small_fullFT_best.pt\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_37/800329554.py:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=scaler is not None):\n","output_type":"stream"},{"name":"stdout","text":"[epoch 3/5] train_loss=1.0483  val_loss=1.0766  val_logloss=1.06523  (1372.0s)\n  -> New best! saved: /kaggle/working/deberta3_small_fullFT_best.pt\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_37/800329554.py:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=scaler is not None):\n","output_type":"stream"},{"name":"stdout","text":"[epoch 4/5] train_loss=1.0132  val_loss=1.1403  val_logloss=1.12716  (1379.4s)\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_37/800329554.py:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=scaler is not None):\n","output_type":"stream"},{"name":"stdout","text":"[epoch 5/5] train_loss=0.9869  val_loss=1.1603  val_logloss=1.14643  (1377.5s)\n  -> Early stopping (patience=2)\n[load] best checkpoint (val_logloss=1.06523)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 550x450 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"[viz] confusion matrix saved to: /kaggle/working/confusion_matrix_val.png\n              precision    recall  f1-score   support\n\n       A win     0.4660    0.3601    0.4062      4013\n       B win     0.4432    0.4704    0.4564      3931\n         Tie     0.4049    0.4814    0.4399      3552\n\n    accuracy                         0.4353     11496\n   macro avg     0.4380    0.4373    0.4342     11496\nweighted avg     0.4393    0.4353    0.4338     11496\n\n[analysis] misclassified: 6492 / 11496\n[save] misclassified samples saved to: /kaggle/working/misclassified_val.csv\n================================================================================\n[Prompt]\n[\"Name all the skills of Disco Elysium and format your answer as follows:\\nName of skill - Relative rating of usefulness from 0 to 100 - Relative rating of interestingness from 0 to 100\"]\n\n[Response A]\n[\"Skills of Disco Elysium:\\n\\n1.   Persuasion - 80\\/100 - 80\\/100\\n2.   Intimidation - 80\\/100 - 80\\/100\\n3.   Investigation - 80\\/100 - 80\\/100\\n4.   Stealth - 80\\/100 - 80\\/100\\n5.   Medicine - 70\\/100 - 70\\/100\\n6.   Persuasion (special) - 90\\/100 - 90\\/100\\n7.   Persuasion (persuasion range) - 80\\/100 - 80\\/100\\n8.   Persuasion (persuasion recharge time) - 70\\/100 - 70\\/100\\n9.   Persuasion (persuasion success rate) - 70\\/100 - 70\\/100\\n10.   Persuasion (persuasion failure rate) - 70\\/100 - ...\n\n[Response B]\n[\"Sure, here are the skills in Disco Elysium, along with their relative ratings of usefulness and interestingness:\\n\\n1. Intelligence - 90% usefulness, 50% interestingness\\n2. Strength - 60% usefulness, 40% interestingness\\n3. Endurance - 80% usefulness, 40% interestingness\\n4. Agility - 70% usefulness, 50% interestingness\\n5. Luck - 50% usefulness, 30% interestingness\\n6. Eccentricity - 70% usefulness, 30% interestingness\\n7. Charisma - 80% usefulness, 50% interestingness\\n8. Perception - 90% u...\n\n✅ True: Tie | ❌ Pred: A win | p=[A:0.419, B:0.271, Tie:0.310]\n================================================================================\n[Prompt]\n[\"how do you do patch a hole in drywall?\"]\n\n[Response A]\n[\"Patching a hole in drywall involves a few steps. Here's a general guide:\\n\\n1. Gather materials: You will need a piece of drywall, drywall mud or joint compound, a putty knife, a corner bead, a drywall saw, sandpaper, and a paint brush or roller.\\n\\n2. Clean the hole: Remove any debris from the hole and ensure it's free of dust or dirt.\\n\\n3. Cut a patch: If the hole is smaller than 2 inches, you can use a self-adhesive patch. If the hole is larger, you will need to cut a piece of drywall to m...\n\n[Response B]\n[\"Patching a hole in drywall involves several steps, including gathering the necessary tools and materials, preparing the area around the hole, applying a patch, and finishing the patch. Here's a detailed guide on how to patch a hole in drywall:\\n\\n1. Gather the necessary tools and materials: To patch a hole in drywall, you'll need a utility knife, a drywall saw, a drywall patch (available in various sizes), joint compound, a putty knife, sandpaper, a tape measure, a pencil, and a primer or pain...\n\n✅ True: B win | ❌ Pred: A win | p=[A:0.425, B:0.324, Tie:0.251]\n================================================================================\n[Prompt]\n[\"whats life\"]\n\n[Response A]\n[\"Life is a complex and multifaceted concept that has been the subject of philosophical, scientific, and religious inquiry for centuries. There is no one definitive answer to the question \\\"What is life?\\\" as the concept encompasses a wide range of phenomena and perspectives.\\n\\nIn general, life is defined as the state of being alive or having the qualities that distinguish living organisms from inanimate matter. Living organisms are characterized by certain essential properties, such as the abi...\n\n[Response B]\n[\"Life is a complex and wondrous phenomenon that encompasses the characteristics and processes associated with living organisms. It is a continuous process of growth, reproduction, adaptation, and response to stimuli. Life can be found on Earth in various forms, ranging from simple single-celled organisms to more complex multi-cellular creatures, including plants and animals.\\n\\nAt its most basic level, life is defined by the presence of complex organic molecules, primarily proteins, lipids, car...\n\n✅ True: Tie | ❌ Pred: A win | p=[A:0.427, B:0.363, Tie:0.211]\n================================================================================\n[Prompt]\n[\"Valerie was cleaning herself up as Emma opened the door and walked in. \\\"What are you looking at,\\\" Emma  whispered, squeezing herself between Valerie and the telescope she'd been looking through. Emma sat on Valerie's lap, and peered through the finder. The telescope was aimed at the apartment building across the way where Lyra and Elysia lived.\"]\n\n[Response A]\n[\"As Emma settled onto Valerie's lap and peered through the telescope's finder, she felt a mixture of excitement and guilt. She knew she shouldn't be spying on her friends, but her curiosity had gotten the better of her. Valerie seemed to sense her inner conflict and placed a reassuring hand on her shoulder.\\n\\n\\\"Don't worry, Emma. We're just having a little fun, and no one's getting hurt,\\\" Valerie whispered, trying to ease Emma's concerns.\\n\\nEmma reluctantly focused the telescope on the apart...\n\n[Response B]\n[\"It seems like Valerie and Emma are quite curious about Lyra and Elysia's activities. Perhaps they are trying to catch a glimpse of something interesting happening in the apartment building.\"]...\n\n✅ True: A win | ❌ Pred: B win | p=[A:0.337, B:0.417, Tie:0.246]\n================================================================================\n[Prompt]\n[\"What is this?\"]\n\n[Response A]\n[\"I'm sorry for the confusion, but I need more context to provide an accurate answer. The provided image is not available. Could you please describe what you are asking about or provide more details? I'm here to help!\"]...\n\n[Response B]\n[\"I'm sorry, but I need more information to understand what \\\"this\\\" refers to. Could you please provide more context or specify your question?\"]...\n\n✅ True: B win | ❌ Pred: Tie | p=[A:0.133, B:0.111, Tie:0.756]\n[save] /kaggle/working/submission.csv\n        id  winner_model_a  winner_model_b  winner_tie\n0   136060        0.302765        0.341284    0.355951\n1   211333        0.331686        0.343298    0.325016\n2  1233961        0.337534        0.333885    0.328581\n[done]\n","output_type":"stream"}],"execution_count":7}]}